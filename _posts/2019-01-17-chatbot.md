---
layout: post
title: "聊天机器人实现(基于相似度)"
categories: 项目
tags: [自然语言处理,  问答系统]
---

* content
{:toc}



## 一、总述

前段时间花了不少精力建立个人NLP项目演示网站（目前放在[lhqshow](http://www.lhqshow.cn:8000/)上），在梳理了所有做过的nlp项目后，觉得需要再集成另外的不同类型的自然语言处理项目，这不由让想起之前接触过的几个猎头－－他们推荐的工作里都涉及到**问答系统**。问答系统我是有一些了解的，但一直没有专门花精力去深入研究，一方面出于自然语言处理领域研究内容太广（宗成庆在其《统计自然语言处理》中就列出了16个方面），没办法眉毛胡子一把抓；另一方面公司业务对问答系统这块没有涉及，所以和项目关联不太密切的技术也就没刻意花时间研究（学海无涯啊！只能按需研究）。那么现在我怎么又想研究它了呢？嘻嘻！主要是最近时间充裕了，另外就是前面说的，目前很多公司都对智能客服有需求，而且目前市面上语音也推出了不少相关产品（像天猫精灵），身为自然语言处理的程序员，自然有必要研究一番。

本文主要讨论聊天机器人，与问答系统可以说是大同小异，其他类似的概念还有智能客服、智能问答等，为了文章一致性，以下统称“聊天机器人”。闲话少叙，接下来我们来谈谈如何撸一个聊天机器人。一般来说，聊天机器人算法流程有如下几种思路：

- 模板匹配：事先定语问题模板及对应的回答
- 基于检索：从文档中搜索与问题相关的内容，再从中抽取与答案相关的部分
- 问题相似度：匹配问题与问题集最相似的记录，返回该记录中的回答
- 文本生成：一般是采用深度学习模型训练文本生成



本文采用的是基于问题相似度的做法，通过计算问题与语料中的所有问题的余弦相似度匹配近似的回答。如果只是想了解下思路，看到这就够了，可以不用往下看了，顶多再百度下余弦计算公式。而如果你想根据该原理实现一个聊天机器人，你还需要考虑:

- 句子的向量表示
- 计算效率
- 内存占用
- 回复多样性


后面我们会一一讨论上面的问题，不过首先你得先准备好以下这些：

- 数据
   - 语料（[小黄鸡](https://github.com/codemayq/chaotbot_corpus_Chinese)）
   - 预训练好的词向量（[wiki百科词向量](https://github.com/Embedding/Chinese-Word-Vectors.git )）

- 工具
   - python3
   - gensim
   - sklearn
   - jieba

​    

以下是最后在前端显示的效果图：

![chatbot_view](/posts_pic/2019-01-17-chatbot/chatbot_view.png)





## 二、句子的向量表示

和其他自然语言处理一样，聊天机器人的第一件事是文本的向量表示，后续所有的模型算法都是基于向量的，这边我们有以下三个可选方案：

- 词袋模型：词频或if-idf
- 词向量：句子里的词的词向量累加(或求平均)
- 句子向量：训练句子向量模型

词袋模型容易造成得到的向量过于稀疏，且只单纯考虑词频，而训练句子向量需要大量的文本，综合考虑下来，笔者采用预训练好的词向量来进行文本向量化处理。





## 三、相似度计算

核心部分就是计算用户输入与语料库的问句之间的相似度，选择最相近的问句并返回其回答，这样基本上就完成了聊天机器人的核心开发。两个向量之间的相似度计算很多，这采用我们耳熟能详的余弦相似度，当然我们也可以采用其他计算方法，如：皮尔逊相关系数、Tanimoto系数等。





## 四、效率优化

### 问题

按照上面的原理基本就可以做出聊天机器人出来，不过若要在生产环境中部署，则你可能要再多考虑一些问题。聊天机器人的一个硬性需求是及时响应，最长不应超过４秒（个人主观感受），否则用户会觉得不耐烦或者认为程序出问题就关掉窗口了。

就我们这个聊天机器人而言，会碰到下面这些问题：

1. 语料较大，挨个计算相似度很慢；
2. 考虑词向量本身的维度（一般是300），所有语料都以向量存储会吃掉大量内存（词向量模型本身就达500M左右，加上你用向量表示的语料，占用的内存很高。通常你的机器上还会跑着其他业务代码，笔者的现实情况是：买的阿里服务器配置为单核2G内存，聊天机器人只是服务中的其中一个应用，还有另外两个）。



### 效率优化

- 预分词。对语料中的所有问题预先分词，这可以明显的改善计算速度。
- 用矩阵计算相似度。矩阵运算的效率远高于for循环，我们这边用Numpy库。
- 随机抽取部分语料来计算相似度。6000～10000条时的速度都还蛮快的，笔者选用8000条。
- 对语料预先分类。对用户输入先分类，然后从语料库中找到与用户相通类别的语料做后续的余弦相似度计算，若得到的语料还是太大，接下来结合上面的随机抽样方法，可以很好地平衡计算效率与准确性。该步骤可以算是质的飞跃。因为语料是没有标签，所以采用无监督文本聚类，类别笔者选择10，没有调参，因为我的目的是分割语料，读者也可以进一步调参。



### 减少内存占用

- 实时构造文本向量。因为笔者的服务器只有2G，所以没用一次性计算好所有文本的向量表示加载到内存，而是实时构造需要计算相似度的语料的向量表示（结合效率优化，每次计算也就构造8000条句子的向量）。
- 批量分类。这一点是在服务器多次死机才发现的。笔者的代码在实例化一个聊天机器人对象时，会根据训练的聚类模型对语料分类（当然，也可以根据模型预先给语料贴上标签），这边不小心在列表里装入了全部语料的向量，发现后改批量分类，然后汇总结果给语料贴标签。







## 五、回复多样性

如果用户两次输入同样的句子，得到回复也一样，那么作为聊天机器人，它是没有”灵魂”的。

在回复多样性上，笔者主要通过两次随机来实现的。第一次随机是从选中的语料中随机抽取8000条样本来计算相似度，每次随机的样本都是不一样的；第二次随机是计算好余弦相似后，从高于相似度阈值的结果的top3中随机抽取一条作为最终的回复。





## 六、流程图与代码

![流程图](/posts_pic/2019-01-17-chatbot/chatbot_流程图.png)

代码:　[chatbot](https://gitee.com/blue666/chatbot)






## 七、延伸

增加爬虫查询天气，股票行情等功能


